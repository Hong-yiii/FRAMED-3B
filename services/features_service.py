"""
Real Features Service for Photo Curation System

Extracts features from actual photo files.
"""

import os
import json
import hashlib
import numpy as np
from typing import Dict, Any
from PIL import Image


class FeaturesService:
    """Real features service that extracts features from actual photos."""

    def __init__(self):
        self.cache_dir = "./data/cache/features"
        os.makedirs(self.cache_dir, exist_ok=True)

    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process preprocessed photos and extract features."""
        print("üîÑ Real Features Service: Extracting features from preprocessed photos")

        batch_id = input_data["batch_id"]
        artifacts = []

        # Handle both preprocess artifacts and photo_index formats
        if "artifacts" in input_data:
            # From preprocess service
            source_artifacts = input_data["artifacts"]
        elif "photo_index" in input_data:
            # Fallback for direct processing
            source_artifacts = [
                {"photo_id": photo["photo_id"], "std_uri": photo["uri"]}
                for photo in input_data["photo_index"]
            ]
        else:
            print("‚ùå No artifacts or photo_index found in input")
            return {"batch_id": batch_id, "artifacts": []}

        for artifact in source_artifacts:
            photo_id = artifact["photo_id"]
            std_uri = artifact.get("std_uri", artifact.get("uri", ""))

            # Check cache first
            cache_key = hashlib.md5(f"{photo_id}_features".encode()).hexdigest()
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")

            if os.path.exists(cache_file):
                print(f"üìã Using cached features for {photo_id[:8]}...")
                with open(cache_file, 'r') as f:
                    cached_data = json.load(f)
                    artifacts.append(cached_data)
                continue

            # Extract features from standardized image
            features = self._extract_features(std_uri, photo_id)

            # Merge with existing artifact data
            complete_artifact = artifact.copy()
            complete_artifact["features"] = features

            artifacts.append(complete_artifact)

            # Cache the result
            with open(cache_file, 'w') as f:
                json.dump(complete_artifact, f, indent=2)

            print(f"‚úÖ Extracted features for {photo_id[:8]}...")

        result = {
            "batch_id": batch_id,
            "artifacts": artifacts
        }

        # Save to intermediate JSONs
        import json
        os.makedirs("intermediateJsons/features", exist_ok=True)
        with open(f"intermediateJsons/features/{batch_id}_features_output.json", 'w') as f:
            json.dump(result, f, indent=2)

        print(f"‚úÖ Real Features Service: Processed {len(artifacts)} photos")
        print(f"üíæ Saved output to intermediateJsons/features/{batch_id}_features_output.json")
        return result

    def _extract_features(self, photo_uri: str, photo_id: str) -> Dict[str, Any]:
        """Extract features from a single photo."""
        try:
            # Open image
            with Image.open(photo_uri) as img:
                width, height = img.size

                # Basic image properties
                aspect_ratio = width / height
                is_portrait = height > width

                # Mock advanced features (replace with real implementations)
                features = {
                    "embeddings": {
                        "clip_L14": f"./data/emb/{photo_id}_clip.npy"
                    },
                    "hashes": {
                        "phash": hashlib.md5(f"phash_{photo_id}".encode()).hexdigest()[:16]
                    },
                    "tech": {
                        "sharpness": 0.7 + np.random.random() * 0.3,
                        "exposure": 0.6 + np.random.random() * 0.3,
                        "noise": 0.1 + np.random.random() * 0.3,
                        "horizon_deg": np.random.normal(0, 2)
                    },
                    "saliency": {
                        "heatmap_uri": f"./data/sal/{photo_id}.png",
                        "neg_space_ratio": 0.2 + np.random.random() * 0.6
                    },
                    "faces": {
                        "count": np.random.choice([0, 1, 2, 3], p=[0.4, 0.3, 0.2, 0.1]),
                        "landmarks_ok": np.random.random() > 0.1
                    },
                    "palette": {
                        "lab_centroids": [
                            [np.random.uniform(20, 80), np.random.uniform(-20, 20), np.random.uniform(-30, 30)]
                            for _ in range(np.random.randint(2, 5))
                        ],
                        "cluster_id": f"pal_{np.random.randint(1, 10):02d}"
                    }
                }

                return features

        except Exception as e:
            print(f"‚ùå Error extracting features from {photo_uri}: {e}")
            # Return minimal features on error
            return {
                "embeddings": {"clip_L14": f"./data/emb/{photo_id}_clip.npy"},
                "hashes": {"phash": hashlib.md5(f"phash_{photo_id}".encode()).hexdigest()[:16]},
                "tech": {"sharpness": 0.5, "exposure": 0.5, "noise": 0.5, "horizon_deg": 0},
                "saliency": {"heatmap_uri": f"./data/sal/{photo_id}.png", "neg_space_ratio": 0.3},
                "faces": {"count": 0, "landmarks_ok": True},
                "palette": {"lab_centroids": [[50, 0, 0]], "cluster_id": "pal_01"}
            }
